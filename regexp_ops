

#Pyspark/Python
from pyspark.sql.types import StringType
data = spark.createDataFrame(["aaaa_12345_xx", "bbbbb_123_yy", "ccc_0123_zzzz", "ddddd_234_zxzxzx"], StringType()).toDF("name")
data.cache()

data.withColumn('num', O.regexp_extract(O.col('name'), r"[a-zA-Z_]+([0-9]*)\w+$", 1)).show(5)
+----------------+-----+
|            name|  num|
+----------------+-----+
|   aaaa_12345_xx|12345|
|    bbbbb_123_yy|  123|
|   ccc_0123_zzzz| 0123|
|ddddd_234_zxzxzx|  234|
+----------------+-----+


-----------------Scenarios--------------------
#PySpark/Python
#Load data with file name & extract file name from full path

import pyspark.sql.functions as O
from pyspark.sql.functions import input_file_name,countDistinct,regexp_extract

regex_str_filename=r".*/([^\/]+)$"

df_hist = spark.read.options(sep=',', header='False').csv('/km/datapath/') \
 .toDF('col1','col2') \
 .withColumn('full_file', O.input_file_name()) \
 .withColumn('filename', O.regexp_extract(O.input_file_name(),regex_str_filename,1) )

+-----+----+-----------------------+----------+
|col1 |col2|full_file              |filename  |
+-----+----+-----------------------+----------+
|11111|abcd|/km/datapath/file01.txt|file01.txt|
|22222|dbcd|/km/datapath/file02.txt|file01.txt|
+-----+----+-----------------------+----------+


#Scala
var tblName="km.table1"
val filterOutWords = Set("INC", "LLC", "A")

var infBaseDataDF = spark.table(tblName)
val keyWordsDF = infBaseDataDF.select("company_name1", "company_name2").
 filter($"company_name1" =!= "").
 withColumn("company_name_drv", regexp_replace(regexp_replace(upper($"company_name1"), "[^a-zA-Z /]+", ""), "[/]+", " ")).
 withColumn("company_name_drv", regexp_replace(regexp_replace(upper($"company_name2"), "[^a-zA-Z /]+", ""), "[/]+", " ")).
 show(4,false)
 
keyWordsDF.select("company_name1_drv","company_name2_drv").rdd.
 map(c1 => {var s1 = c1(0).toString.split(" ").toSet.diff(filterOutWords);
            var s2 = c1(1).toString.split(" ").toSet.diff(filterOutWords);
   (s1.mkString(" "), s2.mkString(" "), s1.intersect(s2).mkString(" ") )
 }).
 toDF("company_name1_drv_2","company_name2_drv_2","matched_words").
 show(100,false)



//-------- Extract Franchise#/Store# from company_name----

var infBaseDataDF = spark.table(tblName)
val keyWordsDF = infBaseDataDF.select("company_name").
 withColumn("company_name_drv", regexp_extract($"company_name", "[\\d]+",0)).
 show(100,false)
 
 
 
 

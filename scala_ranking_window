
//---example----
import org.apache.spark.sql.expressions.Window
import org.apache.spark.sql.functions._

val df = Seq(("a", 10), ("a", 10), ("a", 20), ("b", 30)).toDF("col1", "col2")

val windowSpec = Window.partitionBy("col1").orderBy("col2")

df.withColumn("row_number", row_number().over(windowSpec)).
  withColumn("rank", rank().over(windowSpec)).
  withColumn("dense_rank", dense_rank().over(windowSpec)).
  show()
  
  
  

//-------------- Objective: Get the top zip for every id  -------------------------
//---- Get top rank() with more trans count & high amount by id and zip (due to mulitple txns by id)
val rankSha = org.apache.spark.sql.expressions.Window.partitionBy("id").
  orderBy($"id", desc("tran_cnt"), desc("tran_amt") )

df_trans.select("id","i_phys_zip", "tran_amt").
 groupBy("id","i_phys_zip").agg(count("id").as("tran_cnt"), sum("tran_amt").as("tran_amt")).
 withColumn("rownum", row_number().over(rankSha)).
 filter($"rownum" === 1)
 
 
 
 
 

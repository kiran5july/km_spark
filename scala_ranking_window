
//---example----
import org.apache.spark.sql.expressions.Window
import org.apache.spark.sql.functions._

//--- get rank by single column (No partitioning)
val df = Seq(("a", 10), ("b", 10), ("c", 7), ("d", 16)).toDF("id", "rec_count")

val winRecCount = org.apache.spark.sql.expressions.Window.orderBy(col("rec_count").desc)

df.withColumn("row_number", row_number().over(winRecCount)).
  withColumn("rank", rank().over(winRecCount)).
  withColumn("dense_rank", dense_rank().over(winRecCount)).
  show()

+---+---------+----------+----+----------+
| id|rec_count|row_number|rank|dense_rank|
+---+---------+----------+----+----------+
|  d|       16|         1|   1|         1|
|  b|       10|         2|   2|         2|
|  a|       10|         3|   2|         2|
|  c|        7|         4|   4|         3|
+---+---------+----------+----+----------+


//---- rank separately for each partition column, by another column
val df = Seq(("a", 10), ("a", 10), ("a", 20), ("b", 30), ("b", 16)).toDF("id", "rec_count")

val windowSpec = Window.partitionBy("id").orderBy(col("rec_count").desc)

df.withColumn("row_number", row_number().over(windowSpec)).
  withColumn("rank", rank().over(windowSpec)).
  withColumn("dense_rank", dense_rank().over(windowSpec)).
  show()
  
+---+---------+----------+----+----------+
| id|rec_count|row_number|rank|dense_rank|
+---+---------+----------+----+----------+
|  b|       30|         1|   1|         1|
|  b|       16|         2|   2|         2|
|  a|       20|         1|   1|         1|
|  a|       10|         2|   2|         2|
|  a|       10|         3|   2|         2|
+---+---------+----------+----+----------+
  

//-------------- Objective: Get the top zip for every id  -------------------------
//---- Get top rank() with more trans count & high amount by id and zip (due to mulitple txns by id)
val rankSha = org.apache.spark.sql.expressions.Window.partitionBy("id").
  orderBy($"id", desc("tran_cnt"), desc("tran_amt") )

df_trans.select("id","i_phys_zip", "tran_amt").
 groupBy("id","i_phys_zip").agg(count("id").as("tran_cnt"), sum("tran_amt").as("tran_amt")).
 withColumn("rownum", row_number().over(rankSha)).
 filter($"rownum" === 1)
 
 
 
 
 

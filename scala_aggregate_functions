


List(("aaa",2),("bbb",3),("aaa",1)).
 toDF("name","count").
 groupBy("name").
 agg(count("name").as("count"), sum("count").as("total") ).
 show() 




spark.table("kmdb.orders").
 filter($"extract_date".gt(date_add(current_date,-7))).
 groupBy("extract_date").
 count().
 orderBy($"extract_date".desc).
 show()



//------------------avg-------------------
//sample input
val recDF = Seq( (1, 2), (1,4) , (2,5) , (2,3) ).toDF("id","value")

//---- group & get avg
recDF.groupBy("id").agg(avg("value")).show()

//----- Window to retain other columns
val wId = org.apache.spark.sql.expressions.Window.partitionBy("id")
recDF.withColumn("avg", avg("value").over(wId)).show()


